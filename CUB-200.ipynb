{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, regularizers\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95bb9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "cub_root = r'C:\\Users\\hiero\\OneDrive\\Documents\\SOC-25_Intro-to-Deep-Learning\\CUB_200_2011\\CUB_200_2011'  # dataset root folder\n",
    "images_txt = os.path.join(cub_root, 'images.txt')\n",
    "bbox_txt = os.path.join(cub_root, 'bounding_boxes.txt')\n",
    "images_dir = os.path.join(cub_root, 'images')\n",
    "\n",
    "image_id_to_file = {}\n",
    "with open(images_txt, 'r') as f:\n",
    "    for line in f:\n",
    "        img_id, file_path = line.strip().split()\n",
    "        image_id_to_file[int(img_id)] = file_path\n",
    "\n",
    "bbox_dict = {}\n",
    "with open(bbox_txt, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        img_id, x, y, w, h = int(parts[0]), float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
    "        bbox_dict[img_id] = (x, y, w, h)\n",
    "\n",
    "m = len(image_id_to_file)  \n",
    "images = np.zeros((m, 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "for idx, img_id in enumerate(sorted(image_id_to_file.keys())):\n",
    "    if idx >= m:\n",
    "        break\n",
    "    img_path = os.path.join(images_dir, image_id_to_file[img_id])\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    x, y, w, h = bbox_dict[img_id]\n",
    "    cropped = image.crop((x, y, x + w, y + h))\n",
    "    cropped = cropped.resize((256, 256), Image.LANCZOS)\n",
    "    images[idx] = np.array(cropped)\n",
    "\n",
    "images = images.astype('float32')\n",
    "images=images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a81115",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_txt = os.path.join(cub_root, 'image_class_labels.txt')\n",
    "\n",
    "label_dict = {}\n",
    "with open(labels_txt, 'r') as f:\n",
    "    for line in f:\n",
    "        img_id, class_id = line.strip().split()\n",
    "        label_dict[int(img_id)] = int(class_id)  # class_id is 1-200\n",
    "\n",
    "labels = np.zeros(m, dtype=np.int32)\n",
    "for idx, img_id in enumerate(sorted(image_id_to_file.keys())):\n",
    "    if idx >= m:\n",
    "        break\n",
    "    labels[idx] = label_dict[img_id]\n",
    "\n",
    "labels=labels-1  # Convert to 0-199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_txt = os.path.join(cub_root, 'train_test_split.txt')\n",
    "df = pd.read_csv(split_txt, sep=\" \", header=None, names=['img_id', 'is_train'])\n",
    "train_ids = df[df['is_train'] == 1]['img_id'].values\n",
    "test_ids = df[df['is_train'] == 0]['img_id'].values\n",
    "train_idx = [img_id - 1 for img_id in train_ids]\n",
    "test_idx = [img_id - 1 for img_id in test_ids]\n",
    "train_images = images[train_idx]\n",
    "train_label = labels[train_idx]\n",
    "test_images = images[test_idx]\n",
    "test_label = labels[test_idx]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_images, train_label, test_size=0.1, random_state=42, stratify=train_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be167e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base model\n",
    "base_model = EfficientNetB0(\n",
    "    input_shape=(256, 256, 3),\n",
    "    include_top=False, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "#Create the new model on top\n",
    "num_classes = 200\n",
    "inputs = tf.keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "x = base_model(inputs, training=False) # Use the base model in inference mode\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model for the first phase\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe97531",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # Very low learning rate\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = 10 + fine_tune_epochs\n",
    "\n",
    "history_fine_tune = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "accuracy = np.mean(predicted_classes == test_label)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_auc(y_true, y_pred, classes):\n",
    "    y_true_bin = label_binarize(y_true, classes=classes)\n",
    "    aucs = np.array([roc_auc_score(y_true_bin[:, i], y_pred[:, i]) for i in range(len(classes))])\n",
    "    return np.round(aucs,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3638e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def plot_roc_curves(y_true, y_score, classes, title):\n",
    "    y_true_bin = label_binarize(y_true, classes=classes)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for i, color in zip(range(len(classes)), cycle(['aqua','darkorange','cornflowerblue','green'])):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {classes[i]} (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0,1], [0,1], 'k--', lw=1)\n",
    "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdca7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs=np.array(per_class_auc(test_label,predictions,classes=[0,1,2,3]))\n",
    "print(f\"Neural Network AUCs: {aucs}\")\n",
    "plot_roc_curves(test_label,predictions,classes=[0,1,2,3],title=\"CNN ROC- Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bd4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_img = test_images[20].astype('float32')\n",
    "resized = tf.image.resize(sample_img[None, ...], (224, 224))\n",
    "resized = preprocess_input(resized)\n",
    "pred = model.predict(resized, verbose=0).argmax(axis=-1)[0]\n",
    "\n",
    "plt.imshow(test_images[20].astype('uint8'))\n",
    "plt.axis('off')\n",
    "print('True label:', test_label[20], 'Predicted:', pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
